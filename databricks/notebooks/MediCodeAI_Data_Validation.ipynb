{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c8b14e5-5592-45ab-b2d7-3bd2bc30665b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Accessing the raw file from AWS\n",
    "\n",
    "# Set environment variables for AWS access\n",
    "import os\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'YOUR_AWS_ACCESS_KEY_ID'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'YOUR_AWS_SECRET_ACCESS_KEY'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "\n",
    "print(\"AWS credentials set in environment variables\")\n",
    "\n",
    "# Try to load data from S3\n",
    "try:\n",
    "    # Load the raw EHR data from S3\n",
    "    df = spark.read.csv(\"s3://medicodeai-ehr-data/raw/synthetic_ehr_data.csv\", header=True, inferSchema=True)\n",
    "    \n",
    "    # Create a temporary view for SQL queries\n",
    "    df.createOrReplaceTempView(\"ehr_data\")\n",
    "    \n",
    "    print(f\"‚úÖ Data loaded successfully from S3!\")\n",
    "    print(f\"Shape: {df.count()} rows, {len(df.columns)} columns\")\n",
    "    print(f\"Columns: {df.columns}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(\"\\nSample data:\")\n",
    "    df.show(5)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading from S3: {e}\")\n",
    "    print(\"\\nCreating sample data instead...\")\n",
    "    \n",
    "    # Fallback: Create sample data\n",
    "    from pyspark.sql.types import *\n",
    "    import random\n",
    "    \n",
    "    # Define schema for EHR data\n",
    "    schema = StructType([\n",
    "        StructField(\"patient_id\", StringType(), True),\n",
    "        StructField(\"age\", IntegerType(), True),\n",
    "        StructField(\"gender\", StringType(), True),\n",
    "        StructField(\"diagnosis_text\", StringType(), True),\n",
    "        StructField(\"icd10_code\", StringType(), True),\n",
    "        StructField(\"admission_date\", StringType(), True),\n",
    "        StructField(\"discharge_date\", StringType(), True),\n",
    "        StructField(\"length_of_stay\", IntegerType(), True),\n",
    "        StructField(\"severity_score\", DoubleType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Create sample data\n",
    "    sample_data = []\n",
    "    for i in range(1000):\n",
    "        sample_data.append((\n",
    "            f\"P{i:04d}\",  # patient_id\n",
    "            random.randint(18, 95),  # age\n",
    "            random.choice([\"Male\", \"Female\"]),  # gender\n",
    "            f\"Patient diagnosed with {random.choice(['diabetes', 'hypertension', 'asthma', 'pneumonia', 'heart disease'])}\",  # diagnosis_text\n",
    "            f\"{random.choice(['E11', 'I10', 'J45', 'J18', 'I25'])}.{random.randint(0, 9)}\",  # icd10_code\n",
    "            \"2024-01-01\",  # admission_date\n",
    "            \"2024-01-05\",  # discharge_date\n",
    "            random.randint(1, 30),  # length_of_stay\n",
    "            round(random.uniform(1.0, 10.0), 2)  # severity_score\n",
    "        ))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = spark.createDataFrame(sample_data, schema)\n",
    "    \n",
    "    # Create a temporary view for SQL queries\n",
    "    df.createOrReplaceTempView(\"ehr_data\")\n",
    "    \n",
    "    print(f\"‚úÖ Sample EHR data created successfully!\")\n",
    "    print(f\"Shape: {df.count()} rows, {len(df.columns)} columns\")\n",
    "    print(f\"Columns: {df.columns}\")\n",
    "    \n",
    "    # Show sample data\n",
    "    print(\"\\nSample data:\")\n",
    "    df.show(5)\n",
    "\n",
    "print(\"\\nüéâ Data is ready for SQL validation!\")\n",
    "print(\"You can now run SQL queries on the 'ehr_data' table.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0bf14865-dafd-406d-9675-02e0b3056519",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Save validation summary report as CSV\n",
    "SELECT \n",
    "  'Data Quality Report' as report_type,\n",
    "  CURRENT_TIMESTAMP() as report_timestamp,\n",
    "  (SELECT COUNT(*) FROM ehr_data) as total_records,\n",
    "  (SELECT COUNT(DISTINCT patient_id) FROM ehr_data) as unique_patients,\n",
    "  (SELECT COUNT(DISTINCT icd10_code) FROM ehr_data) as unique_icd10_codes,\n",
    "  (SELECT COUNT(CASE WHEN patient_id IS NOT NULL THEN 1 END) FROM ehr_data) as valid_patient_ids,\n",
    "  (SELECT COUNT(CASE WHEN CAST(age AS INT) >= 0 AND CAST(age AS INT) <= 120 THEN 1 END) FROM ehr_data) as valid_ages,\n",
    "  (SELECT COUNT(CASE WHEN CAST(length_of_stay AS INT) >= 0 THEN 1 END) FROM ehr_data) as valid_length_of_stay,\n",
    "  (SELECT COUNT(CASE WHEN LENGTH(TRIM(diagnosis_text)) >= 10 THEN 1 END) FROM ehr_data) as valid_diagnosis_text,\n",
    "  (SELECT COUNT(CASE WHEN icd10_code REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$' THEN 1 END) FROM ehr_data) as valid_icd10_codes,\n",
    "  (SELECT COUNT(CASE WHEN \n",
    "    patient_id IS NOT NULL AND\n",
    "    diagnosis_text IS NOT NULL AND\n",
    "    icd10_code IS NOT NULL AND\n",
    "    CAST(age AS INT) >= 0 AND CAST(age AS INT) <= 120 AND\n",
    "    CAST(length_of_stay AS INT) >= 0 AND\n",
    "    LENGTH(TRIM(diagnosis_text)) >= 10 AND\n",
    "    icd10_code REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$'\n",
    "  THEN 1 END) FROM ehr_data) as fully_valid_records,\n",
    "  ROUND((SELECT COUNT(CASE WHEN \n",
    "    patient_id IS NOT NULL AND\n",
    "    diagnosis_text IS NOT NULL AND\n",
    "    icd10_code IS NOT NULL AND\n",
    "    CAST(age AS INT) >= 0 AND CAST(age AS INT) <= 120 AND\n",
    "    CAST(length_of_stay AS INT) >= 0 AND\n",
    "    LENGTH(TRIM(diagnosis_text)) >= 10 AND\n",
    "    icd10_code REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$'\n",
    "  THEN 1 END) FROM ehr_data) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as overall_quality_score;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "defa3211-243c-47f4-b177-04415411bd25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Save missing values report as CSV\n",
    "SELECT \n",
    "  'Missing Values' as metric_category,\n",
    "  'patient_id' as field_name,\n",
    "  COUNT(*) - COUNT(patient_id) as invalid_count,\n",
    "  ROUND((COUNT(*) - COUNT(patient_id)) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Missing Values' as metric_category,\n",
    "  'age' as field_name,\n",
    "  COUNT(*) - COUNT(age) as invalid_count,\n",
    "  ROUND((COUNT(*) - COUNT(age)) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Missing Values' as metric_category,\n",
    "  'gender' as field_name,\n",
    "  COUNT(*) - COUNT(gender) as invalid_count,\n",
    "  ROUND((COUNT(*) - COUNT(gender)) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Missing Values' as metric_category,\n",
    "  'diagnosis_text' as field_name,\n",
    "  COUNT(*) - COUNT(diagnosis_text) as invalid_count,\n",
    "  ROUND((COUNT(*) - COUNT(diagnosis_text)) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Missing Values' as metric_category,\n",
    "  'icd10_code' as field_name,\n",
    "  COUNT(*) - COUNT(icd10_code) as invalid_count,\n",
    "  ROUND((COUNT(*) - COUNT(icd10_code)) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdd1926c-eb6e-4cac-a1bd-935cbf812eb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Save data validation report as CSV\n",
    "SELECT \n",
    "  'Data Validation' as metric_category,\n",
    "  'invalid_age' as field_name,\n",
    "  COUNT(CASE WHEN CAST(age AS INT) < 0 OR CAST(age AS INT) > 120 THEN 1 END) as invalid_count,\n",
    "  ROUND(COUNT(CASE WHEN CAST(age AS INT) < 0 OR CAST(age AS INT) > 120 THEN 1 END) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Data Validation' as metric_category,\n",
    "  'negative_length_of_stay' as field_name,\n",
    "  COUNT(CASE WHEN CAST(length_of_stay AS INT) < 0 THEN 1 END) as invalid_count,\n",
    "  ROUND(COUNT(CASE WHEN CAST(length_of_stay AS INT) < 0 THEN 1 END) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Data Validation' as metric_category,\n",
    "  'short_diagnosis_text' as field_name,\n",
    "  COUNT(CASE WHEN LENGTH(TRIM(diagnosis_text)) < 10 THEN 1 END) as invalid_count,\n",
    "  ROUND(COUNT(CASE WHEN LENGTH(TRIM(diagnosis_text)) < 10 THEN 1 END) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "  'Data Validation' as metric_category,\n",
    "  'invalid_icd10_format' as field_name,\n",
    "  COUNT(CASE WHEN icd10_code NOT REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$' THEN 1 END) as invalid_count,\n",
    "  ROUND(COUNT(CASE WHEN icd10_code NOT REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$' THEN 1 END) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1f415f8-2eee-4a2c-8e0a-bd1f1b8fe9d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Save gender distribution report as CSV\n",
    "SELECT \n",
    "  'Gender Distribution' as report_section,\n",
    "  gender,\n",
    "  COUNT(*) as count,\n",
    "  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as percentage\n",
    "FROM ehr_data\n",
    "GROUP BY gender\n",
    "ORDER BY count DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "315f7f5b-dfcd-4ed2-a04a-0a95f33627e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Save age distribution report as CSV\n",
    "SELECT \n",
    "  'Age Distribution' as report_section,\n",
    "  CASE \n",
    "    WHEN CAST(age AS INT) < 18 THEN 'Under 18'\n",
    "    WHEN CAST(age AS INT) BETWEEN 18 AND 30 THEN '18-30'\n",
    "    WHEN CAST(age AS INT) BETWEEN 31 AND 50 THEN '31-50'\n",
    "    WHEN CAST(age AS INT) BETWEEN 51 AND 70 THEN '51-70'\n",
    "    WHEN CAST(age AS INT) > 70 THEN 'Over 70'\n",
    "    ELSE 'Unknown'\n",
    "  END as age_group,\n",
    "  COUNT(*) as count,\n",
    "  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as percentage\n",
    "FROM ehr_data\n",
    "GROUP BY \n",
    "  CASE \n",
    "    WHEN CAST(age AS INT) < 18 THEN 'Under 18'\n",
    "    WHEN CAST(age AS INT) BETWEEN 18 AND 30 THEN '18-30'\n",
    "    WHEN CAST(age AS INT) BETWEEN 31 AND 50 THEN '31-50'\n",
    "    WHEN CAST(age AS INT) BETWEEN 51 AND 70 THEN '51-70'\n",
    "    WHEN CAST(age AS INT) > 70 THEN 'Over 70'\n",
    "    ELSE 'Unknown'\n",
    "  END\n",
    "ORDER BY \n",
    "  CASE age_group\n",
    "    WHEN 'Under 18' THEN 1\n",
    "    WHEN '18-30' THEN 2\n",
    "    WHEN '31-50' THEN 3\n",
    "    WHEN '51-70' THEN 4\n",
    "    WHEN 'Over 70' THEN 5\n",
    "    ELSE 6\n",
    "  END;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "526005b8-d6b1-4780-a769-c17cfbccae2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Save ICD-10 code distribution as CSV\n",
    "SELECT \n",
    "  'ICD-10 Distribution' as report_section,\n",
    "  SUBSTRING(icd10_code, 1, 3) as icd10_category,\n",
    "  COUNT(*) as count,\n",
    "  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as percentage\n",
    "FROM ehr_data\n",
    "GROUP BY SUBSTRING(icd10_code, 1, 3)\n",
    "ORDER BY count DESC;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6192e89a-5f13-4670-b7b1-5dabf587ed9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Save length of stay distribution as CSV\n",
    "SELECT \n",
    "  'Length of Stay Distribution' as report_section,\n",
    "  CASE \n",
    "    WHEN CAST(length_of_stay AS INT) <= 1 THEN '1 day or less'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 2 AND 7 THEN '2-7 days'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 8 AND 14 THEN '8-14 days'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 15 AND 30 THEN '15-30 days'\n",
    "    WHEN CAST(length_of_stay AS INT) > 30 THEN 'Over 30 days'\n",
    "    ELSE 'Unknown'\n",
    "  END as los_group,\n",
    "  COUNT(*) as count,\n",
    "  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as percentage\n",
    "FROM ehr_data\n",
    "GROUP BY \n",
    "  CASE \n",
    "    WHEN CAST(length_of_stay AS INT) <= 1 THEN '1 day or less'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 2 AND 7 THEN '2-7 days'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 8 AND 14 THEN '8-14 days'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 15 AND 30 THEN '15-30 days'\n",
    "    WHEN CAST(length_of_stay AS INT) > 30 THEN 'Over 30 days'\n",
    "    ELSE 'Unknown'\n",
    "  END\n",
    "ORDER BY \n",
    "  CASE los_group\n",
    "    WHEN '1 day or less' THEN 1\n",
    "    WHEN '2-7 days' THEN 2\n",
    "    WHEN '8-14 days' THEN 3\n",
    "    WHEN '15-30 days' THEN 4\n",
    "    WHEN 'Over 30 days' THEN 5\n",
    "    ELSE 6\n",
    "  END;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af1a6267-9468-4b22-9872-de2f9cee20d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Save severity score distribution as CSV\n",
    "SELECT \n",
    "  'Severity Score Distribution' as report_section,\n",
    "  CASE \n",
    "    WHEN CAST(severity_score AS DOUBLE) <= 2.0 THEN 'Low (1-2)'\n",
    "    WHEN CAST(severity_score AS DOUBLE) BETWEEN 2.1 AND 5.0 THEN 'Medium (2.1-5)'\n",
    "    WHEN CAST(severity_score AS DOUBLE) BETWEEN 5.1 AND 8.0 THEN 'High (5.1-8)'\n",
    "    WHEN CAST(severity_score AS DOUBLE) > 8.0 THEN 'Critical (>8)'\n",
    "    ELSE 'Unknown'\n",
    "  END as severity_group,\n",
    "  COUNT(*) as count,\n",
    "  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as percentage\n",
    "FROM ehr_data\n",
    "GROUP BY \n",
    "  CASE \n",
    "    WHEN CAST(severity_score AS DOUBLE) <= 2.0 THEN 'Low (1-2)'\n",
    "    WHEN CAST(severity_score AS DOUBLE) BETWEEN 2.1 AND 5.0 THEN 'Medium (2.1-5)'\n",
    "    WHEN CAST(severity_score AS DOUBLE) BETWEEN 5.1 AND 8.0 THEN 'High (5.1-8)'\n",
    "    WHEN CAST(severity_score AS DOUBLE) > 8.0 THEN 'Critical (>8)'\n",
    "    ELSE 'Unknown'\n",
    "  END\n",
    "ORDER BY \n",
    "  CASE severity_group\n",
    "    WHEN 'Low (1-2)' THEN 1\n",
    "    WHEN 'Medium (2.1-5)' THEN 2\n",
    "    WHEN 'High (5.1-8)' THEN 3\n",
    "    WHEN 'Critical (>8)' THEN 4\n",
    "    ELSE 5\n",
    "  END;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cb337af9-e4bd-4fda-ad95-e01e4890a9c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Save details of invalid records as CSV\n",
    "SELECT \n",
    "  patient_id,\n",
    "  age,\n",
    "  gender,\n",
    "  diagnosis_text,\n",
    "  icd10_code,\n",
    "  length_of_stay,\n",
    "  severity_score,\n",
    "  CASE \n",
    "    WHEN patient_id IS NULL THEN 'Missing patient_id'\n",
    "    WHEN age IS NULL THEN 'Missing age'\n",
    "    WHEN CAST(age AS INT) < 0 OR CAST(age AS INT) > 120 THEN 'Invalid age'\n",
    "    WHEN CAST(length_of_stay AS INT) < 0 THEN 'Negative length of stay'\n",
    "    WHEN LENGTH(TRIM(diagnosis_text)) < 10 THEN 'Short diagnosis text'\n",
    "    WHEN icd10_code NOT REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$' THEN 'Invalid ICD-10 format'\n",
    "    ELSE 'Valid'\n",
    "  END as validation_issue\n",
    "FROM ehr_data\n",
    "WHERE \n",
    "  patient_id IS NULL OR\n",
    "  age IS NULL OR\n",
    "  CAST(age AS INT) < 0 OR \n",
    "  CAST(age AS INT) > 120 OR\n",
    "  CAST(length_of_stay AS INT) < 0 OR\n",
    "  LENGTH(TRIM(diagnosis_text)) < 10 OR\n",
    "  icd10_code NOT REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$'\n",
    "ORDER BY validation_issue;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f32bb33-0d80-4f9c-8345-53a3808aae6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Save report metadata as CSV\n",
    "SELECT \n",
    "  'MediCodeAI Data Validation Report' as report_title,\n",
    "  CURRENT_TIMESTAMP() as generated_at,\n",
    "  (SELECT COUNT(*) FROM ehr_data) as total_records_processed,\n",
    "  (SELECT COUNT(DISTINCT patient_id) FROM ehr_data) as unique_patients,\n",
    "  (SELECT COUNT(DISTINCT icd10_code) FROM ehr_data) as unique_icd10_codes,\n",
    "  (SELECT COUNT(DISTINCT gender) FROM ehr_data) as unique_genders,\n",
    "  ROUND((SELECT COUNT(CASE WHEN \n",
    "    patient_id IS NOT NULL AND\n",
    "    diagnosis_text IS NOT NULL AND\n",
    "    icd10_code IS NOT NULL AND\n",
    "    CAST(age AS INT) >= 0 AND CAST(age AS INT) <= 120 AND\n",
    "    CAST(length_of_stay AS INT) >= 0 AND\n",
    "    LENGTH(TRIM(diagnosis_text)) >= 10 AND\n",
    "    icd10_code REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$'\n",
    "  THEN 1 END) FROM ehr_data) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as overall_data_quality_score;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad7f1dc4-fbb3-46b6-9955-5ef37875d6c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "\n",
    "# Local CSV Export with S3 Upload\n",
    "# This approach avoids Delta format issues in Databricks free edition\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from datetime import datetime\n",
    "\n",
    "# Set AWS credentials\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'YOUR_AWS_ACCESS_KEY_ID'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'YOUR_AWS_SECRET_ACCESS_KEY'\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'us-east-1'\n",
    "\n",
    "print(\"AWS credentials set in environment variables\")\n",
    "\n",
    "# Initialize S3 client\n",
    "s3_client = boto3.client('s3')\n",
    "bucket_name = 'medicodeai-ehr-data'\n",
    "\n",
    "def upload_to_s3(file_path, s3_key):\n",
    "    \"\"\"Upload a file to S3\"\"\"\n",
    "    try:\n",
    "        s3_client.upload_file(file_path, bucket_name, s3_key)\n",
    "        print(f\"‚úÖ Uploaded {file_path} to s3://{bucket_name}/{s3_key}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to upload {file_path}: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "# Create local directory for CSV files\n",
    "local_dir = \"/tmp/validation_reports\"\n",
    "os.makedirs(local_dir, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Created local directory: {local_dir}\")\n",
    "\n",
    "# 1. Generate validation summary\n",
    "print(\"üìä Generating validation summary...\")\n",
    "validation_summary = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  'Data Quality Report' as report_type,\n",
    "  CURRENT_TIMESTAMP() as report_timestamp,\n",
    "  (SELECT COUNT(*) FROM ehr_data) as total_records,\n",
    "  (SELECT COUNT(DISTINCT patient_id) FROM ehr_data) as unique_patients,\n",
    "  (SELECT COUNT(DISTINCT icd10_code) FROM ehr_data) as unique_icd10_codes,\n",
    "  (SELECT COUNT(CASE WHEN patient_id IS NOT NULL THEN 1 END) FROM ehr_data) as valid_patient_ids,\n",
    "  (SELECT COUNT(CASE WHEN CAST(age AS INT) >= 0 AND CAST(age AS INT) <= 120 THEN 1 END) FROM ehr_data) as valid_ages,\n",
    "  (SELECT COUNT(CASE WHEN CAST(length_of_stay AS INT) >= 0 THEN 1 END) FROM ehr_data) as valid_length_of_stay,\n",
    "  (SELECT COUNT(CASE WHEN LENGTH(TRIM(diagnosis_text)) >= 10 THEN 1 END) FROM ehr_data) as valid_diagnosis_text,\n",
    "  (SELECT COUNT(CASE WHEN icd10_code REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$' THEN 1 END) FROM ehr_data) as valid_icd10_codes,\n",
    "  (SELECT COUNT(CASE WHEN \n",
    "    patient_id IS NOT NULL AND\n",
    "    diagnosis_text IS NOT NULL AND\n",
    "    icd10_code IS NOT NULL AND\n",
    "    CAST(age AS INT) >= 0 AND CAST(age AS INT) <= 120 AND\n",
    "    CAST(length_of_stay AS INT) >= 0 AND\n",
    "    LENGTH(TRIM(diagnosis_text)) >= 10 AND\n",
    "    icd10_code REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$'\n",
    "  THEN 1 END) FROM ehr_data) as fully_valid_records,\n",
    "  ROUND((SELECT COUNT(CASE WHEN \n",
    "    patient_id IS NOT NULL AND\n",
    "    diagnosis_text IS NOT NULL AND\n",
    "    icd10_code IS NOT NULL AND\n",
    "    CAST(age AS INT) >= 0 AND CAST(age AS INT) <= 120 AND\n",
    "    CAST(length_of_stay AS INT) >= 0 AND\n",
    "    LENGTH(TRIM(diagnosis_text)) >= 10 AND\n",
    "    icd10_code REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$'\n",
    "  THEN 1 END) FROM ehr_data) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as overall_quality_score\n",
    "\"\"\")\n",
    "\n",
    "# Convert to pandas and save locally\n",
    "validation_summary_pdf = validation_summary.toPandas()\n",
    "local_file = f\"{local_dir}/validation_summary.csv\"\n",
    "validation_summary_pdf.to_csv(local_file, index=False)\n",
    "upload_to_s3(local_file, \"raw/databricks_validation_reports/validation_summary.csv\")\n",
    "\n",
    "# 2. Generate missing values report\n",
    "print(\"üìä Generating missing values report...\")\n",
    "missing_values = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  'Missing Values' as metric_category,\n",
    "  'patient_id' as field_name,\n",
    "  COUNT(*) - COUNT(patient_id) as invalid_count,\n",
    "  ROUND((COUNT(*) - COUNT(patient_id)) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "  'Missing Values' as metric_category,\n",
    "  'age' as field_name,\n",
    "  COUNT(*) - COUNT(age) as invalid_count,\n",
    "  ROUND((COUNT(*) - COUNT(age)) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "  'Missing Values' as metric_category,\n",
    "  'gender' as field_name,\n",
    "  COUNT(*) - COUNT(gender) as invalid_count,\n",
    "  ROUND((COUNT(*) - COUNT(gender)) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "  'Missing Values' as metric_category,\n",
    "  'diagnosis_text' as field_name,\n",
    "  COUNT(*) - COUNT(diagnosis_text) as invalid_count,\n",
    "  ROUND((COUNT(*) - COUNT(diagnosis_text)) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "  'Missing Values' as metric_category,\n",
    "  'icd10_code' as field_name,\n",
    "  COUNT(*) - COUNT(icd10_code) as invalid_count,\n",
    "  ROUND((COUNT(*) - COUNT(icd10_code)) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "\"\"\")\n",
    "\n",
    "missing_values_pdf = missing_values.toPandas()\n",
    "local_file = f\"{local_dir}/missing_values.csv\"\n",
    "missing_values_pdf.to_csv(local_file, index=False)\n",
    "upload_to_s3(local_file, \"raw/databricks_validation_reports/missing_values.csv\")\n",
    "\n",
    "# 3. Generate data validation report\n",
    "print(\"üìä Generating data validation report...\")\n",
    "data_validation = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  'Data Validation' as metric_category,\n",
    "  'invalid_age' as field_name,\n",
    "  COUNT(CASE WHEN CAST(age AS INT) < 0 OR CAST(age AS INT) > 120 THEN 1 END) as invalid_count,\n",
    "  ROUND(COUNT(CASE WHEN CAST(age AS INT) < 0 OR CAST(age AS INT) > 120 THEN 1 END) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "  'Data Validation' as metric_category,\n",
    "  'negative_length_of_stay' as field_name,\n",
    "  COUNT(CASE WHEN CAST(length_of_stay AS INT) < 0 THEN 1 END) as invalid_count,\n",
    "  ROUND(COUNT(CASE WHEN CAST(length_of_stay AS INT) < 0 THEN 1 END) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "  'Data Validation' as metric_category,\n",
    "  'short_diagnosis_text' as field_name,\n",
    "  COUNT(CASE WHEN LENGTH(TRIM(diagnosis_text)) < 10 THEN 1 END) as invalid_count,\n",
    "  ROUND(COUNT(CASE WHEN LENGTH(TRIM(diagnosis_text)) < 10 THEN 1 END) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "UNION ALL\n",
    "SELECT \n",
    "  'Data Validation' as metric_category,\n",
    "  'invalid_icd10_format' as field_name,\n",
    "  COUNT(CASE WHEN icd10_code NOT REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$' THEN 1 END) as invalid_count,\n",
    "  ROUND(COUNT(CASE WHEN icd10_code NOT REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$' THEN 1 END) * 100.0 / COUNT(*), 2) as error_percentage\n",
    "FROM ehr_data\n",
    "\"\"\")\n",
    "\n",
    "data_validation_pdf = data_validation.toPandas()\n",
    "local_file = f\"{local_dir}/data_validation.csv\"\n",
    "data_validation_pdf.to_csv(local_file, index=False)\n",
    "upload_to_s3(local_file, \"raw/databricks_validation_reports/data_validation.csv\")\n",
    "\n",
    "# 4. Generate gender distribution\n",
    "print(\"üìä Generating gender distribution...\")\n",
    "gender_dist = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  'Gender Distribution' as report_section,\n",
    "  gender,\n",
    "  COUNT(*) as count,\n",
    "  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as percentage\n",
    "FROM ehr_data\n",
    "GROUP BY gender\n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "gender_dist_pdf = gender_dist.toPandas()\n",
    "local_file = f\"{local_dir}/gender_distribution.csv\"\n",
    "gender_dist_pdf.to_csv(local_file, index=False)\n",
    "upload_to_s3(local_file, \"raw/databricks_validation_reports/gender_distribution.csv\")\n",
    "\n",
    "# 5. Generate age distribution\n",
    "print(\"üìä Generating age distribution...\")\n",
    "age_dist = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  'Age Distribution' as report_section,\n",
    "  CASE \n",
    "    WHEN CAST(age AS INT) < 18 THEN 'Under 18'\n",
    "    WHEN CAST(age AS INT) BETWEEN 18 AND 30 THEN '18-30'\n",
    "    WHEN CAST(age AS INT) BETWEEN 31 AND 50 THEN '31-50'\n",
    "    WHEN CAST(age AS INT) BETWEEN 51 AND 70 THEN '51-70'\n",
    "    WHEN CAST(age AS INT) > 70 THEN 'Over 70'\n",
    "    ELSE 'Unknown'\n",
    "  END as age_group,\n",
    "  COUNT(*) as count,\n",
    "  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as percentage\n",
    "FROM ehr_data\n",
    "GROUP BY \n",
    "  CASE \n",
    "    WHEN CAST(age AS INT) < 18 THEN 'Under 18'\n",
    "    WHEN CAST(age AS INT) BETWEEN 18 AND 30 THEN '18-30'\n",
    "    WHEN CAST(age AS INT) BETWEEN 31 AND 50 THEN '31-50'\n",
    "    WHEN CAST(age AS INT) BETWEEN 51 AND 70 THEN '51-70'\n",
    "    WHEN CAST(age AS INT) > 70 THEN 'Over 70'\n",
    "    ELSE 'Unknown'\n",
    "  END\n",
    "ORDER BY \n",
    "  CASE age_group\n",
    "    WHEN 'Under 18' THEN 1\n",
    "    WHEN '18-30' THEN 2\n",
    "    WHEN '31-50' THEN 3\n",
    "    WHEN '51-70' THEN 4\n",
    "    WHEN 'Over 70' THEN 5\n",
    "    ELSE 6\n",
    "  END\n",
    "\"\"\")\n",
    "\n",
    "age_dist_pdf = age_dist.toPandas()\n",
    "local_file = f\"{local_dir}/age_distribution.csv\"\n",
    "age_dist_pdf.to_csv(local_file, index=False)\n",
    "upload_to_s3(local_file, \"raw/databricks_validation_reports/age_distribution.csv\")\n",
    "\n",
    "# 6. Generate ICD-10 distribution\n",
    "print(\"üìä Generating ICD-10 distribution...\")\n",
    "icd10_dist = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  'ICD-10 Distribution' as report_section,\n",
    "  SUBSTRING(icd10_code, 1, 3) as icd10_category,\n",
    "  COUNT(*) as count,\n",
    "  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as percentage\n",
    "FROM ehr_data\n",
    "GROUP BY SUBSTRING(icd10_code, 1, 3)\n",
    "ORDER BY count DESC\n",
    "\"\"\")\n",
    "\n",
    "icd10_dist_pdf = icd10_dist.toPandas()\n",
    "local_file = f\"{local_dir}/icd10_distribution.csv\"\n",
    "icd10_dist_pdf.to_csv(local_file, index=False)\n",
    "upload_to_s3(local_file, \"raw/databricks_validation_reports/icd10_distribution.csv\")\n",
    "\n",
    "# 7. Generate length of stay distribution\n",
    "print(\"üìä Generating length of stay distribution...\")\n",
    "los_dist = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  'Length of Stay Distribution' as report_section,\n",
    "  CASE \n",
    "    WHEN CAST(length_of_stay AS INT) <= 1 THEN '1 day or less'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 2 AND 7 THEN '2-7 days'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 8 AND 14 THEN '8-14 days'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 15 AND 30 THEN '15-30 days'\n",
    "    WHEN CAST(length_of_stay AS INT) > 30 THEN 'Over 30 days'\n",
    "    ELSE 'Unknown'\n",
    "  END as los_group,\n",
    "  COUNT(*) as count,\n",
    "  ROUND(COUNT(*) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as percentage\n",
    "FROM ehr_data\n",
    "GROUP BY \n",
    "  CASE \n",
    "    WHEN CAST(length_of_stay AS INT) <= 1 THEN '1 day or less'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 2 AND 7 THEN '2-7 days'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 8 AND 14 THEN '8-14 days'\n",
    "    WHEN CAST(length_of_stay AS INT) BETWEEN 15 AND 30 THEN '15-30 days'\n",
    "    WHEN CAST(length_of_stay AS INT) > 30 THEN 'Over 30 days'\n",
    "    ELSE 'Unknown'\n",
    "  END\n",
    "ORDER BY \n",
    "  CASE los_group\n",
    "    WHEN '1 day or less' THEN 1\n",
    "    WHEN '2-7 days' THEN 2\n",
    "    WHEN '8-14 days' THEN 3\n",
    "    WHEN '15-30 days' THEN 4\n",
    "    WHEN 'Over 30 days' THEN 5\n",
    "    ELSE 6\n",
    "  END\n",
    "\"\"\")\n",
    "\n",
    "los_dist_pdf = los_dist.toPandas()\n",
    "local_file = f\"{local_dir}/length_of_stay_distribution.csv\"\n",
    "los_dist_pdf.to_csv(local_file, index=False)\n",
    "upload_to_s3(local_file, \"raw/databricks_validation_reports/length_of_stay_distribution.csv\")\n",
    "\n",
    "# 8. Generate report metadata\n",
    "print(\"üìä Generating report metadata...\")\n",
    "metadata = spark.sql(\"\"\"\n",
    "SELECT \n",
    "  'MediCodeAI Data Validation Report' as report_title,\n",
    "  CURRENT_TIMESTAMP() as generated_at,\n",
    "  (SELECT COUNT(*) FROM ehr_data) as total_records_processed,\n",
    "  (SELECT COUNT(DISTINCT patient_id) FROM ehr_data) as unique_patients,\n",
    "  (SELECT COUNT(DISTINCT icd10_code) FROM ehr_data) as unique_icd10_codes,\n",
    "  (SELECT COUNT(DISTINCT gender) FROM ehr_data) as unique_genders,\n",
    "  ROUND((SELECT COUNT(CASE WHEN \n",
    "    patient_id IS NOT NULL AND\n",
    "    diagnosis_text IS NOT NULL AND\n",
    "    icd10_code IS NOT NULL AND\n",
    "    CAST(age AS INT) >= 0 AND CAST(age AS INT) <= 120 AND\n",
    "    CAST(length_of_stay AS INT) >= 0 AND\n",
    "    LENGTH(TRIM(diagnosis_text)) >= 10 AND\n",
    "    icd10_code REGEXP '^[A-Z][0-9]{2}\\\\.[0-9X]{1,2}$'\n",
    "  THEN 1 END) FROM ehr_data) * 100.0 / (SELECT COUNT(*) FROM ehr_data), 2) as overall_data_quality_score\n",
    "\"\"\")\n",
    "\n",
    "metadata_pdf = metadata.toPandas()\n",
    "local_file = f\"{local_dir}/report_metadata.csv\"\n",
    "metadata_pdf.to_csv(local_file, index=False)\n",
    "upload_to_s3(local_file, \"raw/databricks_validation_reports/report_metadata.csv\")\n",
    "\n",
    "# Clean up local files\n",
    "import shutil\n",
    "shutil.rmtree(local_dir)\n",
    "\n",
    "print(\"‚úÖ All validation reports generated and uploaded to S3!\")\n",
    "print(\"üìÅ Location: s3://medicodeai-ehr-data/raw/databricks_validation_reports/\")\n",
    "print(\"üìä Files created:\")\n",
    "print(\"   - validation_summary.csv\")\n",
    "print(\"   - missing_values.csv\")\n",
    "print(\"   - data_validation.csv\")\n",
    "print(\"   - gender_distribution.csv\")\n",
    "print(\"   - age_distribution.csv\")\n",
    "print(\"   - icd10_distribution.csv\")\n",
    "print(\"   - length_of_stay_distribution.csv\")\n",
    "print(\"   - report_metadata.csv\")\n",
    "print(\"üßπ Local temporary files cleaned up\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e405a3b-e417-4f1f-8e4d-0bfa92b20e9e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "MediCodeAI_Data_Validation",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
